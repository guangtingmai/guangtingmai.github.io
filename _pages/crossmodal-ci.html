---
layout: archive
title: "CrossModal-CI"
permalink: /crossmodal-ci/
author_profile: true
---
<p align="left">
  <img src="https://guangtingmai.github.io/images/Blausen_0244_CochlearImplant_01.png" width="31%">
  <img src="https://guangtingmai.github.io/images/lipreading.jpg" width="36%">
  <br>
</p>
<p><span style="font-size: 11.7pt;line-height: 1.4;display: block">A <a href="https://en.wikipedia.org/wiki/Cochlear_implant">
  cochlear implant</a> (CI) is a neuro-prothesis that has helped <a href="https://pubs.aip.org/asa/jel/article/2/7/077201/2844572/Celebrating-the-one-millionth-cochlear-implanta">
  over 1 million deaf people worldwide restore their hearing</a>. This is achieved by transmitting sound vibrations into electrical stimulation that (re)activates 
  cochlear cells to send neural impulses to the auditory cortex. However, electrical stimulation is artificial which does not convey sufficient auditory 
  inputs as in typical hearing. Speech communication remains a huge challenge for CI recipients in day-to-day complex, noisy listening environments (at 
  school/work, in streets/restaurants/train stations, meeting with families and friends). CI recipients often use visual speech cues (e.g., lip-reading) 
  to compensate for these auditory barriers to help with communications. However, mechanisms underlying how their different sensory (auditory and visual) 
  systems work together to integrate audiovisual speech are still unclear. It also remains unclear how interactions between these different systems change 
  or 'reorganise' over time and how reorganisation predicts future speech comprehension outcomes.</span></p>
<p><span style="font-size: 11.7pt;line-height: 1.4;display: block;margin-bottom: 0.3vh">Our <a href="https://wellcome.org/research-funding/funding-portfolio/funded-grants?f%5B0%5D=funding_scheme_grants_awarded%3AEarly-Career%20Awards">
  Wellcome Trust funded ECA project</a> (fEC:£1.6m) promises to conduct a series of cross-sectional and longitudinal experiments in adult CI 
  recipients. We will combine brain imaging of <a href="https://en.wikipedia.org/wiki/Electroencephalography">electroencephalography (EEG)</a> (real-time neural activity with 
  millisecond precision) and high-density fNIRS/<a href="https://www.nature.com/articles/pr2017107">diffuse optical tomography (HD-DOT)</a> (recording 
  blood oxygenation level at specific brain regions) to measure CI recipients’ neural responses to audio and visual speech – how they differ from typical hearing, 
  change over time and are modulated to improve speech comprehension. We will thus, scientifically, showcase example processes of 
  <a href="https://en.wikipedia.org/wiki/Cross_modal_plasticity">cross-modal neuroplasticity</a> (how sensory systems with different modalities, e.g., 
  audition and vision, change the way they interact with each other in the brain) in humans with sensory impairment or deprivation after rehabilitation.
<p><span style="font-size: 11.7pt;line-height: 1.4;display: block;margin-bottom: 0.3vh"><strong>Wider implications</strong>, e.g., outcomes from 
  multimodal imaging and clinical practicality (not just for CI recipients) may be expected. We may provide evidence for the potential power for monitoring 
  and prognosis of speech and language comprehension outcomes using tools like EEG combined with portable HD-DOT compared to techniques commonly used but less 
  physically or financially practical/accessible (e.g., MRI/fMRI) under many circumstances (for children/people who cannot stay still in the scanner or with 
  implanted electronic/metallic devices, when large-scale (f)MRI esp longitudinal screening is not always fiscally affordable, or when portable or bedside monitoring 
  is required). This is particularly useful for many whose <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1616963/full">
  behavioural data are not easy to be reliably captured</a> to reflect actual speech comprehension. We may also provide rigorous, consequential neuromodulation 
  evidence for future techniques researchers could develop to support or supplement existing speech and language therapies; in the longer run, for not only people 
  with hard-of-hearing but also those with conditions like aphasia, developmental disorders, neurodivergence, or neurodegeneration.
<p align="left">
  <img src="https://guangtingmai.github.io/images/diversity.png" width="38%">
</p>
  <br>
<p><span style="font-size: 14pt;line-height: 0.5;display: block;margin-bottom: 0.14vh"><strong>Funders (2025-2031):</strong></span></p>
<p align="left">
  <img src="https://guangtingmai.github.io/images/wellcome trust.png" width="11%">
  &emsp;&emsp;
  <img src="https://guangtingmai.github.io/images/mrc_cbu.png" width="35%">
</p>

