---
layout: archive
title: "CrossModal-CI"
permalink: /crossmodal-ci/
author_profile: true
---
<p align="left">
  <img src="https://guangtingmai.github.io/images/Blausen_0244_CochlearImplant_01.png" width="31%">
  <img src="https://guangtingmai.github.io/images/lipreading.jpg" width="36%">
  <br>
</p>
<p><span style="font-size: 12pt;line-height: 1.45;display: block;margin-bottom: 0.14vh">A <a href="https://en.wikipedia.org/wiki/Cochlear_implant">
  cochlear implant</a> (CI) is a neuro-prothesis that helps people with severe hearing loss to access sounds. CI transmits sound vibrations into 
  electrical stimulation that (re)activates cochlea cells and sends neural signals to the auditory cortex. However, electrical stimulation is 
  artificial which does not provide natural and sufficient auditory inputs as in typically hearing individuals. It remains a huge challenge for 
  CI recipients during speech communication in day-to-day complex, noisy listening environments (at school/work, in streets/restaurants/train stations, 
  meeting with families and friends etc). CI recipients often use visual speech cues (e.g., lip-reading) to compensate for these auditory barriers to help 
  with communications. However, mechanisms underlying how their different sensory (auditory and visual) systems work together to integrate audiovisual 
  speech are still not clear. It also remains unclear how interactions between these different systems change or 'reorganise' over time and how 
  reorganisation relates to or predicts future speech comprehension outcomes.</span></p>
<p><span style="font-size: 12pt;line-height: 1.45;display: block;margin-bottom: 0.14vh">Our <a href="https://wellcome.org/research-funding/funding-portfolio/funded-grants?f%5B0%5D=funding_scheme_grants_awarded%3AEarly-Career%20Awards">
  Wellcome Trust funded ECA project</a> (2025-2031, fEC: £1.6m) promises to conduct a series of cross-sectional and longitudinal experiments in adult CI 
  recipients. We will combine brain imaging of <a href="https://en.wikipedia.org/wiki/Electroencephalography">EEG</a> (with millisecond precision to capture 
  real-time responses) and high-density fNIRS/<a href="https://www.nature.com/articles/pr2017107">diffuse optical tomography (DOT)</a> (capturing blood 
  oxygenation level at specific brain regions) to measure CI recipients’ neural tracking and responses to audio and visual speech – how these 
  responses differ from typical hearing, how they could change over time and be modulated to improve speech comprehension. We will thus, 
  scientifically, showcase example processes of <a href="https://en.wikipedia.org/wiki/Cross_modal_plasticity">cross-modal neuroplasticity</a> 
  (evolvement of neural interactions between modalities, i.e., audition and vision) in humans with sensory impairment or deprivation after 
  rehabilitation.
<p><span style="font-size: 12pt;line-height: 1.45;display: block;margin-bottom: 0.14vh"><strong>Wider implications</strong>, e.g., outcomes from 
  multimodal imaging and clinical practicality (for not just CI recipients) may be expected. We may provide evidence for the power for monitoring 
  and prognosis of speech and language comprehension outcomes using neuroimaging tools, e.g., EEG combined with portable and high-density fNIRS/DOT 
  compared to tools commonly used but less physically or financially practical/accessible (e.g., MRI/fMRI) for treatments on a wide range of 
  clinical individuals (children or infants who cannot stay still in the scanner, people implanted with electronic/metallic devices, those with 
  physical disabilities or mental anxiety, in situations where large-scale (f)MRI screening is not considered as fiscally affordable or cost-effective, etc). 
  This is particularly useful for many whose <a href="https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1616963/full">behavioural 
  data are not easy to be reliably captured</a> to reflect actual speech comprehension. We may also provide rigorous, consequential neuromodulation 
  evidence for future techniques researchers could develop to support/aid or supplement the existing speech and language therapy; in the longer run, 
  for not only people with hard-of-hearing but also those with other conditions such as aphasia, developmental disorders, neurodivergence, or neurodegeneration.
<p align="left">
  <img src="https://guangtingmai.github.io/images/diversity.png" width="38%">
  <br>
</p>
