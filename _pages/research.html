---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---
<p><span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.5;display: block;margin-bottom: 0.01vh">My interests focus on three brain processes as lenses to 
  understand typical and <i>atypical</i> human speech processing: <strong>(1) ‘neural tracking’</strong> (how brain signals align and respond to millisecond-scale acoustic 
  and linguistic features) of continuous speech; <strong>(2) functional connectivity</strong> between cortical (sensory and higher-order cognitive and 
  language-related) regions; and <strong>(3) inter-brain synchrony</strong> (brain-to-brain ‘communication’) during interpersonal interactions. 
  I am keen to understand how these processes are shaped/altered by sensory auditory or higher-level cognitive/language comprehension disorders, 
  and what roles they may play when the brain reorganises to compensate for these disorders. I am also keen to understand whether and how neural tracking
  may <i>causally</i> be related to (i.e., consequentially modulate) speech comprehension in clinical individuals. I combine neuroimaging methods of 
  <strong>electroencephalography</strong> (EEG) (measuring neural tracking) and <strong>functional near infrared spectroscopy</strong> (fNIRS) 
  (measuring functional connectivity and inter-brain synchrony).</span></p>
<p align="center">
  <img src="https://guangtingmai.github.io/images/brain_processes.png" width="91%">
</p>
<p><span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.3;display: block;margin-bottom: 0.05vh">I am parts of some ongoing projects that look into these processes in aphasic or cochlear implanted individuals:</span></p>
<p>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.5;display: block;margin-bottom: 0.25vh">&emsp;&emsp;&emsp;<a href="https://guangtingmai.github.io/crossmodal-ci/"><strong>- Neural tracking of audiovisual speech in cochlear-implanted adults</strong></a> <span style="font-size:10pt;">(with Dr <a href="https://www.mrc-cbu.cam.ac.uk/people/matt.davis/">Matt Davis</a>)</span></span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.5;display: block;margin-bottom: 0.05vh">&emsp;&emsp;&emsp;<strong>- Neural tracking of auditory speech in post-stroke aphasia</strong> <span style="font-size:10pt;">(PI Dr <a href="https://profiles.ucl.ac.uk/82001-holly-robson">Holly Robson</a>)</span></span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.5;display: block;margin-bottom: 0.05vh">&emsp;&emsp;&emsp;<a href="https://guangtingmai.github.io/interbrain-sync/"><strong>- Inter-brain synchrony during mother-child interactions</strong></a> <span style="font-size:10pt;">(PI Prof <a href="https://www.nottingham.ac.uk/Medicine/people/douglas.hartley">Doug Hartley</a>)</span></span>
</p>
<p><span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.3;display: block;margin-bottom: 0.05vh">Previously, I did studies that explore neural speech tracking in typical listening or age-related hearing loss:</span></p>
<p>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.5;display: block;margin-bottom: 0.05vh">&emsp;&emsp;&emsp;<a href="https://guangtingmai.github.io/neuraltrack-typical/"><strong>- Neural tracking of auditory speech in typically listening adults</strong></a></span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.5;display: block;margin-bottom: 0.25vh">&emsp;&emsp;&emsp;<a href="https://guangtingmai.github.io/neuraltrack-hearingloss/"><strong>- Neural tracking of auditory speech in adults with age-related hearing loss</strong></a></span>
</p>
<p><span style="font-size: 11.5pt;font-family: Tahoma;line-height: 1.5;display: block;">Hopefully these pieces of work could advance understanding of brain processing of speech and 
  also contribute to developing useful clinical tools for objectively monitoring speech comprehension outcomes, esp when reliable behavioural measures are not easy 
  to obtain in many clinical individuals; for the long term, contribute to bases for neuroscience-inspired rehabilitation to support - not limited to hearing loss 
  or aphasia but wider - neuropsychological conditions (e.g., neurodivergence, neurodegeneration) when day-to-day speech comprehension and communication become 
  challenging.</span></p>
<br>

<p><span style="font-size: 15pt;font-family: Tahoma;line-height: 1;display: block;margin-bottom: 0"><strong>Publications</strong></span></p>
<p><span style="font-size: 11.5pt;font-family: Tahoma;line-height: 0.6;display: block;"><a href="https://scholar.google.com/citations?user=bCQ03mIAAAAJ&hl=en">Google Scholar >></a></span></p>
<br>

<p><span style="font-size: 15pt;font-family: Tahoma;line-height: 1;display: block;margin-bottom: 0"><strong>Main advisors/collaborators</strong></span></p>
<p>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;">Dr <a href="https://www.mrc-cbu.cam.ac.uk/people/matt.davis/">Matt Davis</a> (Cambridge)</span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;">Dr <a href="https://www.mrc-cbu.cam.ac.uk/people/bob.carlyon/">Bob Carlyon</a> (Cambridge)</span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;">Prof <a href="https://www.nottingham.ac.uk/Medicine/people/douglas.hartley">Douglas Hartley</a> (Nottingham)</span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;">Dr <a href="https://profiles.ucl.ac.uk/82001-holly-robson">Holly Robson</a> (UCL)</span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;">Dr <a href="https://profiles.ucl.ac.uk/71137-emily-upton">Emily Upton</a> (UCL)</span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;">Prof <a href="https://www.ncl.ac.uk/medical-sciences/people/profile/timgriffiths.html">Tim Griffiths</a> (Newcastle/UCL)</span>
</p>
<br>

<p><span style="font-size: 15pt;font-family: Tahoma;line-height: 1;display: block;margin-bottom: 0"><strong>Major research links</strong></span></p>
<p>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;"><a href="https://www.mrc-cbu.cam.ac.uk/">MRC Cognition and Brain Sciences Unit</a></span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;"><a href="https://neuroscience.cam.ac.uk/">Cambridge Neuroscience</a></span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;"><a href="https://www.hearing-research.group.cam.ac.uk/">Cambridge Hearing Group</a></span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;"><a href="https://www.languagesciences.cam.ac.uk/">Cambridge Language Sciences</a></span>
  <span style="font-size: 11.5pt;font-family: Tahoma;line-height: 2;display: block;"><a href="https://www.ucl.ac.uk/brain-sciences/pals/research/language-and-cognition">UCL Language and Cognition</a></span>
  <span style="font-size: 11.5pt;line-height: 2;display: block;"><a href="https://www.ucl.ac.uk/brain-sciences/pals/research/speech-hearing-and-phonetic-sciences">UCL SHaPS</a></span>
  <span style="font-size: 11.5pt;line-height: 2;display: block;"><a href="https://nottinghambrc.nihr.ac.uk/research/hearing/">Nottingham Hearing Sciences</a></span>
</p>
